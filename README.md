# Resume Optimization Agent ğŸ“„

<div align="center">
  <img src="readmepics/MainLogo.png" alt="Resume Optimization Agent" width="800"/>

  **AI-powered career advisor to optimize your resume and find relevant jobs**

  [![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
  [![LangChain](https://img.shields.io/badge/langchain-0.1.0+-purple.svg)](https://langchain.com)
  [![Claude Sonnet 4](https://img.shields.io/badge/claude-sonnet--4-orange.svg)](https://anthropic.com)
  [![Streamlit](https://img.shields.io/badge/streamlit-1.30.0+-red.svg)](https://streamlit.io)
  [![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
</div>

---

## ğŸ¯ Overview

An AI-powered career advisor that helps job seekers optimize their resumes and find relevant job opportunities through intelligent analysis and personalized recommendations using Claude Sonnet 4 and LangChain.

**Key Features:**
- ğŸ” **Resume Parsing** - Extract structured data from PDF, DOCX, and TXT files
- ğŸ“Š **Gap Analysis** - Compare resumes against jobs to identify skill gaps
- âœ¨ **AI Optimization** - Claude Sonnet 4-powered content improvements
- ğŸ¯ **ATS Scoring** - Evaluate and improve Applicant Tracking System compatibility
- ğŸ’¬ **Context Memory** - Maintains conversation state across multiple interactions
- ğŸ”§ **10 Specialized Tools** - Purpose-built agent tools for resume optimization

---

## ğŸ—ï¸ System Architecture

<div align="center">
  <img src="readmepics/Architecture Diagram.png" alt="System Architecture" width="700"/>
</div>

### Architecture Components

The system is built on a **modular, tool-based architecture** with four main layers:

#### 1. **UI Layer (Streamlit Interface)**
- File upload and resume management
- Interactive chat interface
- Real-time session state debugging
- Context-aware user experience

#### 2. **Agent Layer (LangChain + Claude Sonnet 4)**
- **LangChain Agent Orchestrator**: Coordinates tool selection and execution
- **Claude Sonnet 4 API**: Powers intelligent analysis and content generation
- **Memory Storage (SQLite)**: Persists conversation history and context
- **Conversation History**: Maintains multi-turn dialogue context

#### 3. **Tool Layer (10 Specialized Tools)**
- **Resume Parser**: Extracts structured data from documents
- **Job Analyzer**: Analyzes job descriptions and requirements
- **Gap Analyzer**: Compares resumes to job requirements
- **Resume Optimizer**: Rewrites content for better job matches
- **Cover Letter Generator**: Creates personalized cover letters
- **Application Tracker**: Manages job application history

#### 4. **Data Layer**
- **SQLite DB**: Stores applications, resumes, and job data
- **File Storage**: Manages uploaded PDF/DOCX files
- **Vector Store**: Optional ChromaDB for semantic search

---

## ğŸ”„ Data Flow

<div align="center">
  <img src="readmepics/Data Flow.png" alt="Data Flow Diagram" width="700"/>
</div>

### Process Flow Explanation

#### User Layer (TO-DO)
1. **Upload Resume PDF** â†’ Sends file to Agent System
2. **Provides Job Preferences** â†’ Communicates requirements to Agent
3. **Reviews Optimized Resume** â†’ Receives enhanced version (TO-45)

#### Agent System (TO-20)
1. **Parses Resume** â†’ Extracts structured data from PDF
2. **Searches Jobs** â†’ Queries Indeed/LinkedIn for matching positions
3. **Optimizes Content** â†’ Uses Claude API to generate improved version

#### External Services
- **Claude API (LLM Processing)** â†’ Analyzes and generates content
- **File Storage (PDF/DOCX files)** â†’ Stores original and optimized resumes
- **Database (Application Tracking)** â†’ Persists job applications and matches

This **asynchronous workflow** ensures the agent can handle multiple requests efficiently while maintaining context across conversations.

---

## ğŸš€ Features

### Core Capabilities

#### Resume Management
- âœ… **Multi-format parsing**: PDF, DOCX, TXT support
- âœ… **Structured extraction**: Contact info, skills, experience, education
- âœ… **Version tracking**: Manage multiple resume variants
- âœ… **Session caching**: Instant access to parsed data

#### Job Analysis
- âœ… **Requirement extraction**: Automatically identifies must-have skills
- âœ… **Keyword identification**: Detects ATS-critical terms
- âœ… **Experience level detection**: Matches seniority requirements
- âœ… **Company insights**: Analyzes job descriptions for cultural fit

#### Intelligent Comparison
- âœ… **Gap analysis**: Identifies missing skills and qualifications
- âœ… **Match scoring**: 0-100% compatibility rating
- âœ… **Partial matching**: Recognizes transferable skills
- âœ… **Priority ranking**: Highlights most important gaps

#### Content Optimization
- âœ… **Section rewriting**: Optimizes summaries, bullets, skills
- âœ… **Keyword incorporation**: Naturally integrates ATS keywords
- âœ… **Achievement focus**: Emphasizes quantifiable results
- âœ… **ATS compatibility**: Ensures parsing-friendly formatting

#### Context Memory System ğŸ†•
- âœ… **Resume persistence**: Remembers uploaded files across conversation
- âœ… **Parsed data caching**: Instant retrieval without re-parsing
- âœ… **Session state tracking**: Maintains job search context
- âœ… **Smart tool selection**: Automatically uses cached data when available

---

## ğŸ› ï¸ Technical Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **LLM** | Claude Sonnet 4 | AI analysis and generation |
| **Agent Framework** | LangChain | Tool orchestration |
| **UI** | Streamlit | Interactive web interface |
| **Database** | SQLite + SQLAlchemy | Data persistence |
| **Validation** | Pydantic | Data modeling |
| **Document Parsing** | PyPDF2, python-docx | Resume extraction |
| **Session Management** | Custom SessionState | Context tracking |

---

## ğŸ“¦ Project Structure

```
ResumeOptimizationAgent/
â”œâ”€â”€ ğŸ“± app.py                        # Streamlit UI with session integration
â”œâ”€â”€ âš™ï¸ config.py                     # Configuration management
â”œâ”€â”€ ğŸ“‹ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ” .env.example                  # Environment template
â”‚
â”œâ”€â”€ ğŸ¤– agent/
â”‚   â”œâ”€â”€ orchestrator.py              # LangChain agent + output parsing
â”‚   â””â”€â”€ prompts.py                   # Context-aware system prompts
â”‚
â”œâ”€â”€ ğŸ”§ tools/
â”‚   â”œâ”€â”€ resume_parser.py             # Resume parsing with caching
â”‚   â”œâ”€â”€ job_analyzer.py              # Job description analysis
â”‚   â”œâ”€â”€ resume_comparator.py         # Gap analysis
â”‚   â”œâ”€â”€ resume_optimizer.py          # Content optimization
â”‚   â””â”€â”€ session_tools.py             # ğŸ†• Context awareness tools
â”‚
â”œâ”€â”€ ğŸ“Š models/
â”‚   â”œâ”€â”€ schemas.py                   # Pydantic data models
â”‚   â””â”€â”€ database.py                  # SQLAlchemy ORM
â”‚
â”œâ”€â”€ ğŸ§° utils/
â”‚   â”œâ”€â”€ helpers.py                   # Utility functions
â”‚   â””â”€â”€ session_state.py             # ğŸ†• Session state manager
â”‚
â”œâ”€â”€ ğŸ’¾ data/
â”‚   â”œâ”€â”€ resumes/                     # Uploaded files
â”‚   â”œâ”€â”€ generated/                   # Optimized content
â”‚   â””â”€â”€ applications.db              # SQLite database
â”‚
â””â”€â”€ ğŸ“š Documentation/
    â”œâ”€â”€ README.md                    # This file
    â”œâ”€â”€ QUICKSTART.md                # 5-minute setup guide
    â”œâ”€â”€ CONTEXT_MEMORY_FIX.md        # Context memory implementation
    â””â”€â”€ DEBUGGING_REPORT.md          # Tool calling fixes
```

---

## ğŸ¬ Installation

### Prerequisites
- Python 3.10 or higher
- Anthropic API key ([Get one here](https://console.anthropic.com))

### Quick Setup (5 Minutes)

```bash
# 1. Clone the repository
git clone https://github.com/frankmark94/ResumeOptimizationAgent.git
cd ResumeOptimizationAgent

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure API key
cp .env.example .env
nano .env  # Add your ANTHROPIC_API_KEY

# 5. Initialize database
python -c "from models.database import init_db; init_db()"

# 6. Launch!
streamlit run app.py
```

The app will automatically open at `http://localhost:8501` ğŸ‰

---

## ğŸ’¡ Usage Guide

### Quick Start

1. **Upload Your Resume**
   - Use sidebar file uploader
   - Supports PDF, DOCX, TXT
   - Click "Parse Resume Now"

2. **Ask Questions**
   ```
   "Analyze my resume and highlight my strengths"
   "What are my top 5 skills?"
   "How many years of experience do I have?"
   ```

3. **Compare to Jobs**
   ```
   "I'm applying for Senior Product Manager at Amazon.
    Here's the job description: [paste text]"
   ```

4. **Get Optimizations**
   ```
   "Optimize my professional summary for this role"
   "Generate 5 achievement-focused bullets for my current position"
   "Check my ATS compatibility for keywords: AWS, Python, Agile"
   ```

### Example Conversation Flow

```
You: [Upload resume.pdf]
Agent: âœ… Resume uploaded and parsed!

You: "What stands out about my resume?"
Agent: "Your cloud architecture experience and AWS expertise are strong selling points..."

You: "I'm applying for this job: [paste Senior PM role at Google]"
Agent: "Your resume matches 78% with this role. Key gaps: Data Science, Roadmapping..."

You: "Optimize my summary for this job"
Agent: [Provides rewritten summary with Google PM keywords]

You: "Generate better bullet points for my Pegasystems role"
Agent: [Creates 5 achievement-focused bullets with metrics]
```

---

## ğŸ§° Agent Tools (10 Total)

| Tool | Purpose | Input | Output |
|------|---------|-------|--------|
| `check_resume_status` ğŸ†• | Check if resume uploaded | None | Resume status, file path |
| `get_session_context` ğŸ†• | Get conversation state | None | Session context summary |
| `parse_resume` | Extract resume data | File path | Structured JSON |
| `analyze_job_description` | Analyze job posting | Job text | Requirements, keywords |
| `extract_job_keywords` | Get technical terms | Job text | Keyword list |
| `compare_resume_to_job` | Gap analysis | Resume + Job | Match score, gaps |
| `calculate_match_score` | Quick scoring | Skills lists | Percentage match |
| `optimize_resume_section` | Rewrite content | Section + requirements | Optimized text |
| `generate_resume_bullets` | Create bullets | Role + skills | Bullet point list |
| `improve_ats_compatibility` | ATS analysis | Resume text | ATS score, tips |

### Tool Calling Example

```python
# Agent automatically does this:
1. check_resume_status()  # See if resume already uploaded
2. parse_resume()         # Extract data (uses cached if available)
3. analyze_job_description(job_text)  # Extract requirements
4. compare_resume_to_job(resume, job)  # Calculate match
5. optimize_resume_section(section, requirements)  # Improve content
```

---

## ğŸ†• Context Memory System

### Problem Solved
Previously, the agent would ask for the resume file path repeatedly, even after upload. This created a frustrating user experience.

### Solution
Implemented a **comprehensive session state management system** that:

- âœ… Tracks uploaded resume files across conversation turns
- âœ… Caches parsed resume data to avoid re-parsing
- âœ… Maintains conversation context and user profile
- âœ… Provides tools for the agent to check session state
- âœ… Automatically uses cached data when available

### How It Works

```python
# User uploads resume
session.set_resume(file_path, parsed_data)

# User asks: "What are my skills?"
agent.check_resume_status()  # Sees has_resume=true
agent.parse_resume()  # Uses cached data (instant!)
# Response uses cached data without asking for file again âœ…
```

### Debug Panel

Open **"ğŸ” Session Debug Info"** in the sidebar to see:
- Resume uploaded: âœ…/âŒ
- File path: `/path/to/resume.pdf`
- Parsed: âœ…/âŒ
- Job provided: âœ…/âŒ
- Recent activity log

See [`CONTEXT_MEMORY_FIX.md`](docs/CONTEXT_MEMORY_FIX.md) for complete implementation details.

---

## âš™ï¸ Configuration

Edit `config.py` to customize:

```python
# LLM Settings
model_name = "claude-sonnet-4-20250514"  # Claude model
temperature = 0.7                         # Response creativity (0.0-1.0)
max_tokens = 4096                         # Response length

# Database
database_url = "sqlite:///./data/applications.db"

# File Paths
resume_dir = "data/resumes"
generated_dir = "data/generated"
```

---

## ğŸ”‘ API Keys

### Required
- **Anthropic API Key**: [Get it here](https://console.anthropic.com)
  ```env
  ANTHROPIC_API_KEY=sk-ant-api03-xxxxx
  ```

### Optional (Phase 2 - Job Search)
- Indeed API Key
- LinkedIn API Key
- Adzuna API credentials

---

## ğŸ§ª Testing

### Run Test Scripts

```bash
# Test agent tool calling
python test_agent_tool_calling.py

# Test response parsing
python test_response_parsing.py

# Debug prompt structure
python debug_prompt_structure.py
```

### Manual Testing Checklist

- [ ] Upload resume â†’ verify stored in session debug panel
- [ ] Parse resume â†’ ask "what stands out?" â†’ should NOT ask for file again
- [ ] Parse resume twice â†’ second time uses cached data (instant)
- [ ] Click "New Conversation" â†’ session resets correctly
- [ ] Multi-turn conversation maintains context

---

## ğŸš§ Roadmap

### âœ… Phase 1: MVP (Complete)
- Resume parsing and analysis
- Job description analysis
- Gap analysis and comparison
- Content optimization
- Streamlit UI
- **Context memory system** ğŸ†•
- **Tool calling fixes** ğŸ†•

### ğŸ”„ Phase 2: Job Search (In Progress)
- Automated job search from APIs (Indeed, LinkedIn)
- Job ranking by relevance
- Application tracking system
- Resume version management

### ğŸ“… Phase 3: Advanced Features
- Cover letter generation
- Semantic job matching with ChromaDB
- Export to PDF/DOCX with formatting
- Interview preparation suggestions
- Email drafting for outreach
- Chrome extension for job saves

---

## ğŸ› Troubleshooting

### Common Issues

**Import Errors**
```bash
pip install -r requirements.txt --upgrade
```

**API Key Errors**
```bash
# Verify .env file
cat .env | grep ANTHROPIC_API_KEY
```

**Database Errors**
```bash
python -c "from models.database import init_db; init_db()"
```

**Agent Not Using Tools**
- Check system prompt in `agent/prompts.py`
- Verify tools registered in `agent/orchestrator.py`
- See [`DEBUGGING_REPORT.md`](docs/DEBUGGING_REPORT.md) for tool calling fixes

**Session State Not Persisting**
- Check debug panel shows resume uploaded
- Verify `session.set_resume()` called on upload
- See [`CONTEXT_MEMORY_FIX.md`](docs/CONTEXT_MEMORY_FIX.md) for details

---

## ğŸ“š Documentation

- **[QUICKSTART.md](docs/QUICKSTART.md)** - 5-minute setup guide
- **[CONTEXT_MEMORY_FIX.md](docs/CONTEXT_MEMORY_FIX.md)** - Context memory implementation
- **[DEBUGGING_REPORT.md](docs/DEBUGGING_REPORT.md)** - Tool calling & rendering fixes
- **[PROJECT_SUMMARY.md](docs/PROJECT_SUMMARY.md)** - Complete implementation overview

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

---

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com) - Agent orchestration framework
- Powered by [Anthropic Claude](https://anthropic.com) - Sonnet 4 LLM
- UI with [Streamlit](https://streamlit.io) - Interactive web apps
- Inspired by the need for better job search tools

---

## ğŸ“ Support

- ğŸ› [Report Issues](https://github.com/frankmark94/ResumeOptimizationAgent/issues)
- ğŸ’¬ [Discussions](https://github.com/frankmark94/ResumeOptimizationAgent/discussions)
- ğŸ“§ Contact: [GitHub Profile](https://github.com/frankmark94)

---

<div align="center">
  <strong>Built with â¤ï¸ using LangChain, Claude Sonnet 4, and Streamlit</strong>

  â­ Star this repo if you find it helpful!
</div>
